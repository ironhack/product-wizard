# üßô‚Äç‚ôÇÔ∏è Product Wizard - Ironhack Sales Enablement Assistant

> An AI-powered assistant that provides accurate, citation-backed information about Ironhack courses for sales teams during live calls with prospective students.

## üéØ Overview

Product Wizard is a Slack-integrated assistant built on OpenAI's GPT-4o model with file search capabilities. It helps Ironhack's sales team provide accurate course information with proper citations during phone calls with prospects.

### Key Features
- ‚úÖ **Zero Fabrication Policy** - Only provides documented information
- ‚úÖ **Perfect Citations** - References specific curriculum documents
- ‚úÖ **Sales-Ready Responses** - Conversational tone for phone calls
- ‚úÖ **Variant Awareness** - Distinguishes Remote vs Berlin programs
- ‚úÖ **Multi-Course Support** - All Ironhack bootcamps and programs

## üìÅ Project Structure

```
product-wizard/
‚îÇ
‚îú‚îÄ‚îÄ src/                     # üöÄ Main Application
‚îÇ   ‚îú‚îÄ‚îÄ app.py              # Slack middleware application for Heroku
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py         # Package initialization
‚îÇ
‚îú‚îÄ‚îÄ docs/                    # üìù Documentation & Prompt Versions
‚îÇ   ‚îî‚îÄ‚îÄ development/        # Development documentation
‚îÇ       ‚îú‚îÄ‚îÄ MASTER_PROMPT_V*.md  # Historical prompt versions
‚îÇ       ‚îî‚îÄ‚îÄ MASTER_PROMPT_V6_ENHANCED_TOOLS.md  # Current (V6)
‚îÇ
‚îú‚îÄ‚îÄ knowledge_base/          # üìö Course Information Database
‚îÇ   ‚îú‚îÄ‚îÄ database/           # Original curriculum files (.md format)
‚îÇ   ‚îú‚îÄ‚îÄ database_txt/       # Processed curriculum files (.txt format)
‚îÇ   ‚îî‚îÄ‚îÄ index.yaml         # Course structure for web visualization
‚îÇ
‚îú‚îÄ‚îÄ tests/                   # üß™ Testing & Validation
‚îÇ   ‚îú‚îÄ‚îÄ test_config.py      # Centralized test configuration with dotenv
‚îÇ   ‚îú‚îÄ‚îÄ model_tests/        # Model comparison and upgrade tests
‚îÇ   ‚îú‚îÄ‚îÄ results/            # Test output files
‚îÇ   ‚îî‚îÄ‚îÄ archive/            # Old test files
‚îÇ
‚îú‚îÄ‚îÄ tools/                   # üõ†Ô∏è Utility Scripts
‚îÇ   ‚îú‚îÄ‚îÄ deploy_prompt.py    # Deploy prompts to OpenAI assistant
‚îÇ   ‚îú‚îÄ‚îÄ assistant_tester.py # Assistant testing utilities
‚îÇ   ‚îî‚îÄ‚îÄ *.py               # Other tools and utilities
‚îú‚îÄ‚îÄ scripts/                # üìú Helper Scripts  
‚îú‚îÄ‚îÄ archive/                # üì¶ Archived Files
‚îÇ
‚îú‚îÄ‚îÄ .env.example            # Environment variables template
‚îú‚îÄ‚îÄ Procfile               # Heroku deployment configuration
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies (includes dotenv)
‚îú‚îÄ‚îÄ runtime.txt           # Python version specification
‚îî‚îÄ‚îÄ README.md             # This documentation
```

## üöÄ Quick Start

### 1. Setup Environment Variables
```bash
# Copy environment variables template
cp .env.example .env

# Edit .env with your credentials
# - OPENAI_API_KEY
# - OPENAI_ASSISTANT_ID
# - SLACK_BOT_TOKEN (for Heroku deployment)
# - SLACK_SIGNING_SECRET (for Heroku deployment)
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run the Application (Local Development)
```bash
python src/app.py
```

### 4. Test the Assistant
```bash
# Quick test
python tools/assistant_tester.py

# Citation quality test
python tests/test_citations_clean.py
```

## üß™ Testing Suite

### Available Tests

| Test | Purpose | Command |
|------|---------|---------|
| **Citation Quality** | Verify proper file citations | `python tests/test_citations_clean.py` |
| **Fabrication Check** | Ensure no invented information | `python tests/test_sales_scenarios.py` |
| **Model Comparison** | Compare different GPT models | `python tests/model_tests/model_comparison_test.py` |

### Test Results
All test results are saved to `tests/results/` with timestamps and detailed analysis.

## üìä Performance Metrics

### Current Performance (V5)
- **Fabrication Rate**: 0% (Zero fabrications detected)
- **Citation Quality**: 9.3/10 (Excellent file attribution)
- **Sales Readiness**: 95% (Ready for production use)
- **Model**: GPT-4o (Latest OpenAI model)

### Key Achievements
- ‚úÖ Eliminated all major fabrications (DevOps GCP/Jenkins, fake schedules)
- ‚úÖ Perfect citations with full document names
- ‚úÖ Variant-aware responses (Remote vs Berlin)
- ‚úÖ Sales-appropriate conversational tone

## üéØ Usage Examples

### For Sales Team

**Question**: "What technologies are covered in the Web Development bootcamp?"

**Response**: 
> According to the Web Development bootcamp curriculum, the program covers a comprehensive range of technologies. For the Berlin onsite bootcamp, the tools used include HTML & CSS, JavaScript (ES6+), TypeScript, Node.js, Express.js, Next.js, React, MongoDB... „ÄêWeb_Dev_Berlin_onsite_bootcamp_2025_07.txt„Äë

**Benefits**:
- Clear source attribution
- Specific curriculum reference
- Variant distinction (Berlin vs Remote)
- Professional but conversational tone

## üîß Configuration

### Environment Variables (config.py)
```python
# OpenAI Configuration
OPENAI_API_KEY = "your_api_key_here"
OPENAI_ASSISTANT_ID = "your_assistant_id_here"

# Slack Configuration (optional)
SLACK_BOT_TOKEN = "your_slack_token_here"
SLACK_SIGNING_SECRET = "your_signing_secret_here"
```

### Assistant Configuration
- **Model**: GPT-4o (latest OpenAI model)
- **Tools**: File search enabled
- **Vector Store**: Attached with all curriculum documents
- **Prompt**: MASTER_PROMPT.md (V5 Enhanced Citations)

## üìö Documentation

### Development Reports
- **[Final Report](docs/reports/FINAL_REPORT.md)** - Complete project analysis
- **[Citations Report](docs/reports/CITATIONS_FINAL_REPORT.md)** - Citation system analysis
- **[Model Comparison](docs/reports/MODEL_COMPARISON_FINAL.md)** - GPT model testing results

### Development History
- **[Prompt Evolution](docs/development/)** - MASTER_PROMPT V1-V5 development
- **[Test Archive](tests/archive/)** - Historical test files

## üõ†Ô∏è Development

### Adding New Tests
1. Use `tools/test_utils.py` for common functionality
2. Save results to `tests/results/`
3. Follow the established naming convention

### Updating the Prompt
1. Edit `MASTER_PROMPT.md`
2. Test with `python tests/test_citations_clean.py`
3. Verify no regressions with full test suite

### Model Updates
1. Update `config.py` with new model name
2. Run model comparison tests
3. Update documentation with performance metrics

## üîí Security

- **Never commit config.py** (contains API keys)
- **Use config.example.py** as template
- **Keep API keys secure** and rotate regularly
- **Monitor usage** for unexpected costs

## üìû Support

For technical issues:
1. Check test results in `tests/results/`
2. Run diagnostic tools in `tools/`
3. Review documentation in `docs/`

## üèÜ Success Metrics

- **Zero Fabrications**: No invented information
- **Perfect Citations**: Full document attribution
- **Sales Ready**: Appropriate for live calls
- **Accurate Information**: 100% curriculum-based
- **Professional Tone**: Conversational but authoritative

---

*Last Updated: Current (V5 Enhanced Citations)*
*Status: Production Ready*