Course content  
**Data Analytics**

**Table of contents**

 - [Course Duration](#course-duration)
 - [Course Overview](#course-overview)
 - [General Structure](#general-structure)
 - [Learning Outcomes](#learning-outcomes)
 - [Course Details](#course-details)
   - [Unit 0: Prework (50 hours)](#unit-0-prework-50-hours)
   - [Unit 1: Python Fundamentals (40 hours)](#unit-1-python-fundamentals-40-hours)
   - [Unit 2: Data Manipulation (40 hours)](#unit-2-data-manipulation-40-hours)
   - [Unit 3: Databases and SQL (40 hours)](#unit-3-databases-and-sql-40-hours)
   - [Unit 4: EDA and Data Visualisation (40 hours)](#unit-4-eda-and-data-visualisation-40-hours)
   - [Unit 5: Project 1 (40 hours)](#unit-5-project-1-40-hours)
   - [Unit 6: Statistics (40 hours)](#unit-6-statistics-40-hours)
   - [Unit 7: Advanced SQL (40 hours)](#unit-7-advanced-sql-40-hours)
   - [Unit 8: Advanced Python (40 hours)](#unit-8-advanced-python-40-hours)
   - [Unit 9: Data Retrieval (40 hours)](#unit-9-data-retrieval-40-hours)
   - [Unit 10: Project 2 (40 hours)](#unit-10-project-2)
   - [Unit 11: Machine Learning I (40 hours)](#unit-11-machine-learning-i-40-hours)
   - [Unit 12: Machine Learning II (40 hours)](#unit-12-machine-learning-ii-40-hours)
   - [Unit 13: Applied Mathematics (40 hours)](#unit-13-applied-mathematics-40-hours)
   - [Unit 14-15: Final/Capstone project (80 hours)](#finalcapstone-project-80-hours)

## **Course Duration**

Duration: 600 hours \+ 50 hours of prework

## **Course Overview**

The Data Analytics course is created to transition beginners into highly skilled data analysts capable of navigating the vast landscape of data analysis with confidence and expertise. 

Commencing with an introduction to Python, the foundational language for data analysis, the curriculum sets up the groundwork for complex data manipulation and analysis. As the course progresses, learners will explore advanced topics in data wrangling, retrieval techniques, and database management, utilizing tools such as Pandas for data manipulation, SQL for database interaction, and APIs for data retrieval from external sources. 

The curriculum is designed to cover the entire data analytics process, from data collection and cleaning to exploratory data analysis, statistical inference, and machine learning, culminating in a comprehensive understanding of how to turn raw data into actionable insights. Alongside technical skills, the course emphasizes the importance of storytelling with data, enabling participants to communicate findings effectively to stakeholders. Participants will gain hands-on experience through a blend of theoretical learning and practical exercises, including labs, mini-projects, and group activities designed to reinforce learning and encourage problem-solving in real-world contexts.

By the end of this intensive bootcamp, learners will have developed a robust portfolio of projects demonstrating their readiness to tackle data challenges in a professional environment, equipped with the skills to continue learning and adapting in the fast-evolving field of data analytics.

## **General Structure**

* **Class Format**: Engaging mix of interactive lectures, hands-on lab sessions, collaborative projects, and individual assessments.  
* **Materials Provided**: Lecture slides, coding exercises, project templates, additional reading materials, and access to a wide range of development tools.  
* **Tools Used**: Python, Git, GitHub, Pandas, NumPy, SQL, APIs, Web Scraping, Tableau, Machine Learning libraries (Scikit Learn), Statistics (SciPy), Large Language Models (LLMs), Cloud Computing platforms.  
* **Feedback Mechanism**: Continuous feedback during lab sessions, peer reviews during projects, and formal evaluations via quizzes and lab assignments.

## **Learning Outcomes**

By the end of this course, participants will be able to:

* Identify business problems and opportunities for improvement through data analysis, and apply appropriate data analytics techniques to generate meaningful insights and inform decision-making.  
* Explain and implement the data analytics process in full from acquiring, cleaning, processing and exploring data, to visualizing and communicating insights.  
* Demonstrate proficiency in cleaning, transforming, and processing data using techniques such as joins, grouping, aggregation, and missing data imputation, to create clean and usable datasets for data analysis and modeling.  
* Conduct exploratory data analysis, including univariate, bivariate and multivariate analysis techniques, to understand the characteristics, patterns, and relationships in the data, and understand how these results impact the data analysis process.  
* Apply key preprocessing techniques for predictive analytics, including feature engineering, feature selection, data balancing, scaling and normalization, handling missing values, and transforming skewed data to effectively prepare and enhance datasets for modeling, considering the specific data and model requirements.  
* Apply basic concepts of probability and statistics to data analysis, including descriptive statistics, probability distributions, and hypothesis testing.  
* Identify appropriate machine learning models for specific business problems and data sets.  
* Build and compare predictive models using supervised and unsupervised machine learning algorithms for classification and regression tasks, and understand how to choose the best-performing model for a given task.  
* Evaluate the performance of predictive models using metrics such as accuracy, precision, recall, or F1-score for classification models, and mean absolute error, mean squared error, R-squared or adjusted R-squared for regression models, and be able to select the appropriate metric based on the specific business problem.  
* Interpret the results of machine learning models and make appropriate adjustments to improve performance.  
* Identify and select the appropriate data visualization methods to effectively communicate insights.  
* Communicate data insights to non-technical stakeholders by using storytelling techniques and creating interactive and informative visualizations using data visualization tools such as Tableau or Power BI  
* Access, extract and manipulate data from relational databases using SQL.  
* Use Python and relevant libraries to extract, clean, manipulate and analyze data from various sources, and create interactive visualizations to present their findings.  
* Extract data from websites using web scraping techniques and tools, as well as understand and use APIs to access data from various sources.  
* Use Command line, Git version control, GitHub, and Gitflow branching model to manage projects with others.  
* Apply Agile methodologies, such as Scrum, to real-world projects that involve participating in different rituals such as daily stand-ups and sprint retrospectives.  
* Write clean, modular, and efficient code following best practices	

## **Course Details**

### **Unit 0: Prework (50 hours)**

**Objective**: The Prework is designed to set a solid foundation for aspiring data professionals, equipping them with the essential skills, tools, and mindset needed for success in the dynamic field of data analytics. This crucial initial phase aims to familiarize participants with the fundamental concepts, technical environment, and learning approaches that will be employed throughout their data analytics journey. By the end of this unit, participants will have a clear understanding of the course objectives, the essential tools for data analysis, and the foundational knowledge of Python programming, preparing them for the more advanced topics in data analytics (and machine learning).

Throughout the prework, learners are engaged in hands-on labs and assessments that reinforce the theoretical knowledge acquired. These practical experiences are essential for developing the skills needed to navigate the Data Analytics landscape effectively.

**Key Topics:**

* Prework introduction and setting up the environment/tools  
* Introduction to Python Programming  
* Introduction to Descriptive Statistics  
* Version control \- Git & GitHub

**Practice & Assessment:**

* 2x Labs  
* 3x Assessments

 

### **Unit 1: Python Fundamentals (40 hours)**

**Objective**: This unit is designed to provide participants with a robust foundational understanding of Python programming, a critical skill in the toolkit of a data analyst. This unit aims to equip learners with the necessary knowledge and skills to write efficient Python code for data analysis tasks. By the end of this unit, participants will have a solid grasp of Python's core data structures, control flow mechanisms, functions, and more advanced concepts like list comprehension, lambda functions, and object-oriented programming (OOP). The unit is structured to ensure participants not only learn Python syntax but also develop the ability to think like a programmer, solving data-related problems and implementing solutions effectively.

**Key Topics:**

* Data structures in Python (lists, dictionaries, set comprehensions) to effectively manipulate and store data  
* Control flow mechanisms such as conditional statements and loops to execute code blocks conditionally or repeatedly, enhancing program logic and efficiency  
* Functions in Python, enabling modular programming, code reuse, and better organization for complex data analysis tasks  
* Lambda functions, map, reduce, and filter for applying functional programming techniques to process collections of data succinctly  
* Data Roles: Understanding different data roles in the industry (Data Analyst, Data Scientist, Data Engineer, etc.), responsibilities, and tools they commonly use.

**Practice & Assessment:**

* 5x Labs  
* 1x Mini project  
* 1x Assessment

 

### **Unit 2: Data Manipulation (40 hours)**

**Objective**: This unit aims to equip participants with the necessary skills to collect, clean, and prepare data for analysis. This unit is designed to teach the art and science of transforming raw data into a format that is ready for analysis, which is a critical step in the data analytics process. By the end of this unit, participants will be proficient in using Pandas for data manipulation, understand the principles of data cleaning and manipulation, and be able to retrieve data from various sources using APIs and web scraping techniques. This foundational knowledge will enable participants to handle and prepare data effectively, setting the stage for insightful data analysis.

**Key Topics:**

* Introduction to Data Wrangling to learn the essentials of manipulating, cleaning, and preparing data for insightful analysis.  
* NumPy for Data Manipulation: Introduction to NumPy arrays, vectorized operations, broadcasting, and performance optimization for numerical computing.  
* Utilization of Pandas, a Python library, for advanced data manipulation tasks, making data cleaning and preparation efficient and effective.  
* Hands-on labs with Pandas to reinforce theoretical knowledge through practical application, enhancing skills in real-world data wrangling.  
* Techniques for cleaning and data manipulation, focusing on handling missing values, outliers, and transforming data for analytical readiness.  
* Structuring and combining data from diverse sources, employing aggregation to derive meaningful insights from data.  
* Retrieval of data using APIs, enabling structured collection of data from various online platforms and services.  
* Web scraping skills for extracting data from web pages, transforming unstructured web data into structured formats for analysis.  
* Application of learned data wrangling skills in a mini-project focused on shark attack data, emphasizing practical problem-solving and application.  
* Completion of a data wrangling technical challenge to assess and reinforce the skills and knowledge acquired throughout the unit.

**Practice & Assessment:**

* 6x Labs  
* 1x Mini project  
* 1x Assessment

### 

### **Unit 3: Databases and SQL (40 hours)**

**Objective**: This unit is designed to immerse participants in the world of databases, specifically focusing on mastering Structured Query Language (SQL), the standard language for relational database management and data manipulation. This unit aims to equip participants with comprehensive skills in creating, querying, and manipulating databases using SQL. By the end of this unit, participants will have a solid understanding of database fundamentals, be proficient in executing complex SQL queries, and capable of integrating SQL with Python for data analytics projects, preparing them for data retrieval and manipulation tasks in real-world scenarios.

**Key Topics:**

* Foundational knowledge about databases and SQL for setting up, querying, and managing relational databases effectively  
* MySQL Database Creation techniques for establishing databases, including table creation and database connection management  
* Crafting basic SQL queries to retrieve, filter, sort, and aggregate data, enabling precise data analysis and reporting  
* Advanced SQL functionalities, including data aggregation for summary reports and data transformation to meet analytical requirements  
* Utilization of SQL joins to merge rows from two or more tables based on related columns, enhancing data consolidation and analysis  
* Employment of SQL subqueries to construct complex queries for dynamic data retrieval and manipulation, increasing query flexibility  
* Creation and use of temporary tables, views, and Common Table Expressions (CTEs) to manage query results and simplify SQL queries  
* Application of SQL window functions for partitioning data sets and performing calculations across data partitions for in-depth data analysis  
* Integration of SQL databases with Python to combine the analytical power of Python with SQL's data management capabilities for advanced data analysis projects

**Practice & Assessment:**

* 7x Labs  
* 1x Mini project  
* 1x Assessment

 

### **Unit 4: EDA and Data Visualisation (40 hours)**

**Objective**: This unit is structured to introduce participants to the essential concepts and practices of Exploratory Data Analysis (EDA) and foundational inferential statistics, crucial for making informed decisions based on data insights. This unit aims to equip participants with the analytical skills needed to conduct thorough data analysis, from understanding data distributions and relationships to applying statistical methods to infer trends and patterns. By integrating hands-on projects, labs, and theoretical knowledge, participants will learn to uncover hidden insights in data and apply statistical reasoning to validate hypotheses and inform business strategies.

**Key Topics:**

* Introduction to EDA and Univariate Analysis to uncover insights from single variables within datasets, using graphical and quantitative methods  
* Hands-on EDA Univariate Analysis, applying practical skills to real datasets to understand distributions, central tendency, and variability  
* EDA Bivariate Analysis to explore relationships between two variables, using correlation and visualization techniques for deeper insights  
* Intro to Probability, laying the groundwork for understanding the likelihood of events and the basics of probability theory in data analysis  
* Hypothesis Testing to make informed decisions based on statistical evidence, understanding different tests and their applications in data analysis  
* More on Correlation and Normality, delving deeper into the relationship between variables and the importance of normal distribution in statistical analysis

**Practice & Assessment:**

* 4x Labs

### **Unit 5: Project 1 (40 hours)**

**Objective:** The objective of this project is to synthesize and apply the knowledge and skills learned in previous units into a practical data analytics project. This unit provides students with an opportunity to demonstrate their ability to work with real-world data, apply analytical techniques, and communicate insights effectively.

Students will follow an Agile methodology, engaging in iterative development, collaboration, and problem-solving. By the end of this unit, students will have successfully designed, implemented, and presented a data analytics project, demonstrating their ability to extract, analyze, and visualize data to derive meaningful insights.

Students are expected to apply knowledge from Python Fundamentals, Data Manipulation, Databases & SQL, and EDA & Data Visualization to structure, clean, analyze, and present insights from a dataset.

Key Topics:

* Project Planning: Setting up a project framework using Agile methodologies such as Kanban or Trello to manage tasks and track progress.  
* Data Gathering and Problem Selection: Identifying a real-world dataset or business problem, collecting necessary data, and understanding dataset fields.  
* Data Analysis: Applying exploratory data analysis (EDA), statistical techniques, and data visualization to uncover trends, patterns, and insights.  
* Data Cleaning and Manipulation: Handling missing values, outliers, and performing transformations to ensure data quality.  
* Data Visualization and Storytelling: Using Matplotlib, Seaborn, and/or Tableau to communicate insights effectively through compelling visualizations.  
* Project Presentation: Structuring and delivering a comprehensive presentation outlining the project journey, methodologies used, key findings, and insights.

**Practice & Assessment:**

* 1 Project

### **Unit 6: Statistics (40 hours)**

**Objective:** This unit introduces students to fundamental statistical concepts and methodologies essential for data analysis. Students will learn how to apply statistical techniques to explore data distributions, test hypotheses, and make data-driven decisions. The unit covers both descriptive and inferential statistics, providing a solid foundation for advanced data analysis and machine learning.

By the end of this unit, students will be able to interpret statistical findings, understand probability distributions, conduct hypothesis testing, and evaluate data-driven insights critically.

**Key Topics:**

* Probability & Distributions: Understanding fundamental probability concepts and different types of probability distributions (normal, binomial, Poisson, etc.).  
* Goodness of Fit: Assessing how well a statistical model fits a given dataset.  
* Confidence Intervals: Estimating population parameters using confidence intervals and understanding their implications in statistical inference.  
* Hypothesis Testing I: Categoricals & Correlations: Conducting statistical tests (e.g., chi-square tests) to determine relationships between categorical variables.  
* Hypothesis Testing II: Parametric vs. Non-parametric: Understanding the differences and applications of parametric and non-parametric tests in statistical analysis.  
* Hypothesis Testing III: ANOVA: Performing Analysis of Variance (ANOVA) to compare means across multiple groups.

**Practice & Assessment:**

* 5 Labs  
* 1 Assessment

### **Unit 7: Advanced SQL (40 hours)** 

**Objective**: This unit builds upon foundational SQL knowledge by introducing advanced database techniques and optimizations. Students will explore complex query structures, database indexing, and optimization strategies to enhance performance and scalability. By the end of this unit, students will be proficient in using advanced SQL techniques to manipulate and retrieve data efficiently.

**Key Topics:**

* Subqueries: Writing and optimizing subqueries for data extraction and transformation.  
* Temporary Tables & Indexing: Utilizing temporary tables to store intermediate results and indexing strategies to improve query performance  
* Views, CTEs & Window Functions: Understanding the role of views, common table expressions (CTEs), and window functions for efficient data processing and analysis.  
* SQL Optimization: Learning techniques to enhance query performance, including indexing, query rewriting, and execution plan analysis.  
* SQL Games & Challenges: Students will participate in interactive SQL exercises designed to reinforce advanced query techniques and optimization strategies.

**Practice & Assessment:**

* 5 Labs  
* 1 Quest Presentation

### **Unit 8: Advanced Python (40 hours)**

**Objective:** This unit builds on foundational Python skills by introducing advanced programming concepts essential for building scalable and efficient applications. Students will explore advanced data structures, object-oriented programming, command-line scripting, and key techniques for developing web applications and automating workflows. By the end of this unit, students will be proficient in handling complex programming tasks, structuring code for reusability, and integrating Python with different environments.

**Key Topics:**

* Command Line & Environment Management: Understanding the command line interface, working with terminals, and managing virtual environments.  
* OS Operations & System Interaction: Using Python to navigate the file system, manage processes, and execute system-level commands for automation.

* ### Object-Oriented Programming (OOP): Deep dive into OOP principles such as classes, inheritance, encapsulation, and polymorphism for structuring scalable applications.

* ### Generators & Iterators: Implementing memory-efficient techniques for handling large datasets and optimizing performance.

* ### Error Handling & Debugging: Writing robust code using exception handling and debugging techniques.

* ### Web Application Development: Introduction to building web applications using Streamlit or Flask, and an overview of graphical user interface (GUI) development.

* ### Quest Development: A hands-on challenge to apply all advanced Python concepts in a real-world scenario.

### **Practice & Assessment:**

* ### 5 Labs

* ### 1 Quest Presentation

* ### 1 Assessment

###    **Unit 9: Data Retrieval (40 hours)** 

**Objective:** This unit focuses on methods for extracting, collecting, and integrating data from various sources, including APIs, web scraping, and database connections. Students will learn how to retrieve and process external data efficiently, a crucial skill in data analytics. By the end of this unit, students will be proficient in accessing, extracting, and manipulating structured and unstructured data.

**Key Topics:**

* APIs & Data Retrieval: Understanding APIs, making API requests, and handling API responses using Python.  
* Web Scraping: Extracting structured data from websites using libraries like BeautifulSoup and Scrapy.  
* APIs II: Advanced API authentication, rate-limiting, and handling paginated data.  
* Python-SQL Connection: Connecting Python with SQL databases to query, retrieve, and manipulate data.  
* Midproject Preparation: Applying data retrieval techniques to support the midproject requirements.

**Practice & Assessment:**

* 4 Labs  
* 1 Assessment

### **Unit 10 - Project 2:** 

**Objective:** This unit challenges students to integrate and apply all prior knowledge and skills gained throughout the course in a comprehensive data analytics project. Project 2 serves as a stepping stone toward the final capstone project, reinforcing students’ ability to independently handle real-world data challenges. This project will require students to implement data retrieval, cleaning, manipulation, analysis, visualization, and machine learning techniques while following best practices in storytelling and project management.

By the end of this unit, students will have successfully executed a full data analytics workflow, demonstrating their proficiency in solving data-driven problems and effectively communicating insights.

**Key Topics:**

* Project Planning: Structuring tasks using Agile methodologies, such as Kanban or Trello, for effective workflow management.  
* GitHub Collaboration: Leveraging GitHub for team-based data projects, including repository management, branching strategies, and best practices for version control.  
* Advanced Git Commands: Expanding knowledge of Git commands beyond basics, including rebasing, interactive commits, and resolving merge conflicts.  
* Data Retrieval & Preparation: Extracting data from APIs, web scraping, and connecting to SQL databases to retrieve structured datasets.  
* Data Wrangling & Cleaning: Handling missing values, outliers, and data inconsistencies using Pandas and NumPy.  
* Exploratory Data Analysis (EDA): Conducting univariate, bivariate, and multivariate analysis to derive insights.  
* Machine Learning Implementation: Applying regression or classification models, optimizing hyperparameters, and evaluating model performance.  
* Data Visualization & Storytelling: Creating meaningful visualizations using Matplotlib, Seaborn, or Tableau to present findings clearly.  
* Project Presentation: Delivering a structured report and presentation, outlining methodologies, key findings, and business impact.

**Practice & Assessment:**

* 1 Project

### **Unit 11: Machine Learning I (40 hours)**

**Objective:** This unit introduces the fundamentals of machine learning, focusing on regression techniques. Students will learn how to preprocess data, build regression models, optimize hyperparameters, and evaluate model performance. By the end of this unit, students will be able to develop and fine-tune predictive models for continuous target variables.

**Key Topics:**

* Introduction to Machine Learning: Overview of machine learning concepts, types, and use cases.  
* Feature Engineering & Preprocessing: Handling missing values, encoding categorical data, scaling, and feature selection.  
* Regression Models: Implementing linear regression, multiple regression, and polynomial regression.  
* Model Optimization: Tuning hyperparameters to improve model performance.  
* Model Evaluation Metrics: Using R-squared, Mean Absolute Error (MAE), and Mean Squared Error (MSE) to assess regression models.  
* Hands-on Project: Applying regression models to a real-world dataset.

**Practice & Assessment:**

* 5 Labs  
* 1 Mini Project  
* 1 Assessment

### **Unit 12: Machine Learning II (40 hours)** 

**Objective:** This unit expands on machine learning techniques by focusing on classification models and unsupervised learning. Students will learn how to implement various classification algorithms, handle imbalanced datasets, and explore clustering techniques for pattern discovery. By the end of this unit, students will be able to build and evaluate classification models and apply unsupervised learning techniques to real-world problems.

**Key Topics:**

* Classification Models: Implementing logistic regression, decision trees, random forests, and k-nearest neighbors (KNN).  
* Imbalanced Data Handling: Techniques to address imbalanced datasets, such as SMOTE and class weighting.  
* Hyperparameter Tuning in Classification & Clustering: Using GridSearchCV and RandomizedSearchCV to optimize classification models and clustering algorithms for better performance.  
* Model Evaluation Metrics: Using accuracy, precision, recall, F1-score, and ROC-AUC to evaluate classification performance.  
* Unsupervised Learning: Introduction to clustering techniques such as K-means and hierarchical clustering.

* ### Dimensionality Reduction: Applying PCA (Principal Component Analysis) for feature reduction.

* ### Hands-on Project: Applying classification and clustering models to a real-world dataset.

### **Practice & Assessment:**

* ### 5 Labs

* ### 1 Mini Project

* ### 1 Assessment

###   **Unit 13: Applied Mathematics (40 hours)** 

**Objective:** This unit provides students with a deep understanding of mathematical concepts essential for data science and artificial intelligence. Students will explore numerical computing with NumPy, tensor operations for deep learning, and foundational concepts in cloud computing. Additionally, they will gain an introduction to Large Language Models (LLMs) and their applications. By the end of this unit, students will be equipped with the mathematical and computational skills necessary for advanced analytics and AI-driven projects.

**Key Topics:**

* Advanced NumPy Operations: Exploring NumPy arrays, broadcasting, vectorized operations, and performance optimization techniques.  
* Intro to PyTorch Tensors: Understanding tensor operations, differentiation, and how tensors are used in deep learning models.  
* Mathematical Foundations for AI: Covering essential linear algebra and probability concepts for machine learning and AI.  
* Introduction to Cloud Computing: Overview of cloud infrastructure, cloud service providers, and deployment strategies.  
* BigQuery for Scalable Data Processing: Using Google BigQuery to process and analyze large datasets efficiently in the cloud. Hands-on practice with querying structured data.  
* Large Language Models (LLMs): Understanding the architecture of LLMs, their applications, and how to interact with them via APIs.

**Practice & Assessment:**

* 3 Labs

 

### **Final/Capstone project  (80 hours)**

**Objective**: The objective of the final capstone project is to synthesize and apply the comprehensive range of skills learned throughout the course into an end-to-end data analytics or data science project. This project is an opportunity for participants to demonstrate their ability to tackle real-world data challenges by conducting a thorough analysis from start to finish. Depending on their focus, participants can choose between two case studies:

1. Data Science End-to-End Project This case involves building a predictive model based on a selected business case. The project encompasses the entire data science process, including data collection, cleaning, exploratory data analysis (EDA), feature engineering, model selection and evaluation, and data visualization.  
2. Data Analytics End-to-End Project: This case focuses on performing data analysis and creating a decision-making dashboard, primarily using SQL, Python, and visualization tools like Tableau or Power BI. It covers the full data analysis pipeline, from data collection and cleaning (to feature engineering if ML is used) to statistical analysis, data visualization, and dashboard creation.

This project is an essential culmination of the bootcamp experience, allowing participants to showcase their skills in a practical, real-world setting and prepare a portfolio piece that demonstrates their readiness for a career in data science or data analytics.

**Key Topics:**

* Project Planning \- Setting up a project management framework using tools like Kanban or Trello for tracking progress and managing tasks.  
* AI Topics Discussion (Week 14 & Week 15): Exploring emerging trends in AI, ethical considerations, and real-world applications of advanced machine learning models.  
* Data Gathering and Problem Selection: Identifying a real-world problem to address, collecting necessary data, and understanding the dataset fields.  
* Data Analysis: Applying statistical techniques and data visualization to explore feature relationships and derive insights.  
* Data Cleaning and Manipulation: Handling outliers, missing values, and transforming data for analysis.  
* Machine Learning (if applicable): Employing machine learning techniques for predictive modeling, experimenting with different algorithms, and optimizing model performance.  
* Presentation of Findings: Summarizing findings through statistical summaries, data visualizations, and, where relevant, machine learning model outcomes. This includes creating databases, performing SQL-based analysis, and developing decision-making dashboards.  
* Project Presentation: Delivering a comprehensive presentation that outlines the project journey, methodologies used, key findings, and insights.

**Practice & Assessment:**

* 1 Project

